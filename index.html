<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Agastya Kalra</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images_data/Agastya.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <img src="image_data/akasha.png" alt="University of Waterloo"  width="100">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                
                <name>Agastya Kalra</name>
              </p>
              <p>I am currently a Principal Engineer at <a href="akasha.im">Akasha Imaging</a>, where I am also a founding team member. 
              </p>
              My research interests lie at the intersection of computational imaging, multi-view geometry, and machine learning, especially in the context of visual diversity or robotics. I have published in NeuriPS, ICCV, and CVPR and am a co-inventor on more than a dozen patents in computational imaging. 
              <p>
                
              </p>
              <p style="text-align:center">
                <a href="mailto:agastya@akasha.im">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=tcbzdzAAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/kalraa/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="image_data/Agastya.png"><img style="width:100%;max-width:100%" alt="profile photo" src="image_data/Agastya.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Recent News</heading>
            <p>Update August 28th, 2021: Excited to be giving a <a href="https://scien.stanford.edu/index.php/event/agastya-kalra/">SCIEN talk</a> on October 13th at Stanford!</p>
            <p>Update July 22nd 2021: Our new paper on rotation invariance was accepted to ICCV 2021! Stay tuned...</p>
            
          </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="image_data/PolSeg.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Kalra_Deep_Polarization_Cues_for_Transparent_Object_Segmentation_CVPR_2020_paper.pdf">
                <papertitle>Deep Polarization Cues for Transparent Object Segmentation</papertitle>
              </a>
              <br>
              <strong>Agastya Kalra</strong>, 
              <a href="https://scholar.google.com/citations?user=kzOv34UAAAAJ&hl=en">Vahe Taamazyan</a>, 
              <a href="https://www.linkedin.com/in/supreethrao/">Supreeth Krishna Rao</a>, 
              <a href="https://www.linkedin.com/in/kavenkataraman/">Kartik Venkataraman</a>, 
              <a href="https://web.media.mit.edu/~raskar/">Ramesh Raskar</a> 
              <a href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>
              <br>
              <em>CVPR</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Kalra_Deep_Polarization_Cues_for_Transparent_Object_Segmentation_CVPR_2020_paper.pdf">paper</a>
              /
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Kalra_Deep_Polarization_Cues_CVPR_2020_supplemental.pdf">supplement</a>
              /
              <a href="https://youtu.be/hF64LfsR5Lc">teaser</a>
							/
              <a href="https://www.youtube.com/watch?v=yyEJgdniNYI">video</a>
              /
              <a href="https://youtu.be/7SBNiW_Kh1g">demo</a>
              <br>
              <p>We leverage polarization cues in neural pipelines to improve invarances w.r.t. transparent objects in segmentation and robotic bin picking</p>
              
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="image_data/mnets.png" alt="clean-usnob" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1908.04646">
                <papertitle>MatrixNets: a New Architecture for Object Detection</papertitle>
              </a>
              <br> 
              <a href="https://scholar.google.ca/citations?user=CnxsW1QAAAAJ&hl=en">Abdullah Rashwan</a>,
              <strong>Agastya Kalra</strong>, 
              <a href="https://cs.uwaterloo.ca/~ppoupart/">Pascal Poupart</a>
              <br>
              <em>ICCV workshop</em>, 2019 &nbsp <font color="red"><strong>(Best Paper Shortlist)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1908.04646">Short Paper</a>
              /
              <a href="https://arxiv.org/abs/2001.03194">Long Paper</a>
              /
              <a href="https://github.com/arashwan/matrixnet">Code</a>
              <br>
              <p>We re-architect the Feature Pyramid Networks to improve invariance to aspect ratios and show SOTA performance in COCO test and val.</p>
              
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="image_data/dating.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://nips.cc/Conferences/2018/Schedule?showEvent=11669">
                <papertitle>Photofeeler-D3: A Neural Network with Voter Modeling for Dating Photo Impression Prediction</papertitle>
              </a>
              <br> 
              <strong>Agastya Kalra</strong>, 
              Ben Peterson
              <br>
              <em>arXiv</em>, 2019 
              <br>
              <a href="https://arxiv.org/pdf/1904.07435.pdf">Paper</a>
              /
              <a href="https://www.youtube.com/watch?v=0UdpZV0OXws">Demo</a>
              /
              <a href="https://blog.photofeeler.com/photofeeler-d3/">Article</a>
              /
              <a href="https://blog.deeplearning.ai/blog/the-batch-hotter-dating-profiles-pandas-in-love-compute-for-coronavirus-deepfake-detection-self-driving-cars-run-amok">The Batch</a>
              <br>
              <p>We leverage deep voter modeling to rate dating photos and allow millions of users to select the best dating photo.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="image_data/spn_learning.png" alt="clean-usnob" width="160" >
            </td>
            <td width="75%" valign="middle">
              <a href="https://nips.cc/Conferences/2018/Schedule?showEvent=11669">
                <papertitle>Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks</papertitle>
              </a>
              <br> 
              <a href="https://scholar.google.ca/citations?user=CnxsW1QAAAAJ&hl=en">Abdullah Rashwan</a>,
              <strong>Agastya Kalra</strong>, 
              <a href="https://cs.uwaterloo.ca/~ppoupart/">Pascal Poupart</a>
              <br>
              <em>NeurIPS</em>, 2018 
              <br>
              <a href="https://proceedings.neurips.cc/paper/2018/hash/66121d1f782d29b62a286909165517bc-Abstract.html">Paper</a>
              /
              <a href="https://github.com/kalraa/tachyon">Code</a>
              /
              <a href="https://www.youtube.com/watch?v=_yVjTK0Nzqw">Video</a>
              <br>
              <p>We propose the first successful online structure learning method for gaussian and recurrent Sum-Product Networks.</p>
            </td>
          </tr>

          


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="image_data/Waterloo.png" alt="University of Waterloo"  width="160" height="160">
            </td>
            <td width="75%" valign="center">
              Guest Lecturer and Course Advisor, CS480 (Machine Learning) Fall 2017 with <a href="https://cs.uwaterloo.ca/~y328yu/index.html">Yaoliang Yu</a>.
              <br>
              <br>
              Guest Lecturer and Course Advisor, CS484 (Computer Vision) Fall 2018 with <a href="https://cs.uwaterloo.ca/~yboykov/index.html">Yuri Boykov</a>.
              <br>
              <br>
              Guest Lecturer in Computer Vision and Machine Learning courses with 
                <a href="https://cs.uwaterloo.ca/~ppoupart/">Pascal Poupart</a>,
                <a href="https://cs.uwaterloo.ca/~yboykov/index.html">Yuri Boykov</a>, 
                <a href="https://cs.uwaterloo.ca/~y328yu/index.html">Yaoliang Yu</a>, and
                <a href="https://cs.uwaterloo.ca/~jorchard/uw/">Jeff Orchard</a>.
              
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Template credits: <a href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  
</body>

</html>
